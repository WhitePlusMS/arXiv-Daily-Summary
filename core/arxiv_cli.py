#!/usr/bin/env python3
"""ArXiv æ¯æ—¥è®ºæ–‡æ¨èç³»ç»Ÿ - CLIä¸»ç¨‹åºå…¥å£

æ•´åˆäº†åŸmain.pyçš„åŠŸèƒ½ï¼Œä½¿ç”¨æ–°çš„æ¨¡å—åŒ–æ¶æ„ã€‚
æä¾›å‘½ä»¤è¡Œæ¥å£ï¼Œæ•´åˆè®ºæ–‡æ¨èã€é‚®ä»¶å‘é€å’ŒæŠ¥å‘Šç”Ÿæˆæµç¨‹ã€‚
"""

import os
import sys
import json
from pathlib import Path
from typing import List, Dict, Any, Optional

from loguru import logger
from datetime import datetime, timedelta
from core.arxiv_fetcher import ArxivFetcher
from core.llm_provider import LLMProvider
from core.recommendation_engine import RecommendationEngine
from core.template_renderer import TemplateRenderer
from core.mcp_time_service import MCPTimeService
from core.mcp_time_service import get_current_time
from core.output_manager import OutputManager
from core.common_utils import sanitize_username, format_timezone_date, get_timezone_aware_now
from core.env_config import get_str, get_int, get_bool, get_list, get_float
from core.progress_utils import ProgressTracker
import re

# é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ï¼ˆç”¨äºæ–‡ä»¶è¯»å–ï¼‰
project_root = Path(__file__).parent.parent


class ArxivRecommenderCLI(ProgressTracker):
    """ArXivæ¨èç³»ç»ŸCLIä¸»ç±»ã€‚"""
    
    def __init__(self, username=None):
        """åˆå§‹åŒ–CLIåº”ç”¨ã€‚
        
        Args:
            username: æŒ‡å®šç”¨æˆ·åï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªç”¨æˆ·çš„é…ç½®
        """
        logger.info("ArXivæ¨èç³»ç»Ÿåˆå§‹åŒ–å¼€å§‹")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.username = username  # å­˜å‚¨ç”¨æˆ·å
        self.arxiv_fetcher = None
        self.llm_provider = None
        self.recommendation_engine = None
        self.output_manager = None
        
        # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
        self.research_interests = []
        self.user_profiles = []
        
        # è¿›åº¦è·Ÿè¸ª
        self.task_id = None  # å½“å‰ä»»åŠ¡IDï¼ˆç”¨äºè¿›åº¦æ›´æ–°ï¼‰
        
        # é…ç½®å‚æ•°
        logger.debug("åŠ è½½ç³»ç»Ÿé…ç½®")
        self.config = self._load_config()
        # åŠ è½½ç”¨æˆ·åˆ†ç±»æ ‡ç­¾ï¼Œæ›´æ–°é…ç½®
        self._load_user_categories()
        logger.success(f"ç³»ç»Ÿé…ç½®åŠ è½½å®Œæˆ - ç®€è¦åˆ†æè®ºæ–‡æ•°: {self.config['num_brief_papers']}, è¯¦ç»†åˆ†æ: {self.config['num_detailed_papers']}, åˆ†ç±»æ ‡ç­¾: {self.config['arxiv_categories']}")
        
        # ä½¿ç”¨MCPæ—¶é—´æœåŠ¡è·å–å½“å‰æ—¶é—´å¹¶è®°å½•INFOæ—¥å¿—
        try:
            current_time = get_current_time()
            logger.info(f"ç³»ç»Ÿå¯åŠ¨æ—¶é—´ï¼ˆMCPæ—¶é—´æœåŠ¡ï¼‰: {current_time}")
        except Exception as e:
            logger.warning(f"MCPæ—¶é—´æœåŠ¡è°ƒç”¨å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨æœ¬åœ°æ—¶é—´")
        
    def _load_config(self) -> Dict[str, Any]:
        """ä»é›†ä¸­åŒ– env é…ç½®æ¨¡å—åŠ è½½é…ç½®ã€‚
        
        Returns:
            é…ç½®å­—å…¸
        """
        # é‡æ–°åŠ è½½ .env æ–‡ä»¶ï¼Œç¡®ä¿è·å–æœ€æ–°é…ç½®
        from core.env_config import reload
        reload()
        
        config = {
            # APIé…ç½®
            'dashscope_api_key': get_str('DASHSCOPE_API_KEY', ''),
            'dashscope_base_url': get_str('DASHSCOPE_BASE_URL', 'https://dashscope.aliyuncs.com/compatible-mode/v1'),
            'qwen_model': get_str('QWEN_MODEL', 'qwen-plus'),

            # æä¾›æ–¹ä¸æ¨¡å‹æ˜ å°„ï¼ˆå‰ç«¯éœ€è¦æ„ŸçŸ¥ï¼‰
            'heavy_model_provider': get_str('HEAVY_MODEL_PROVIDER', 'dashscope'),
            'light_model_provider': get_str('LIGHT_MODEL_PROVIDER', get_str('HEAVY_MODEL_PROVIDER', 'dashscope')),
            'qwen_model_light': get_str('QWEN_MODEL_LIGHT', ''),
            
            # ArXivè·å–å™¨é…ç½®
            'arxiv_base_url': get_str('ARXIV_BASE_URL', 'http://export.arxiv.org/api/query'),
            'arxiv_retries': get_int('ARXIV_RETRIES', 3),
            'arxiv_delay': get_int('ARXIV_DELAY', 5),
            # arxiv_categories ç°åœ¨ä»ç”¨æˆ·é…ç½®æ–‡ä»¶ä¸­çš„ category_id å­—æ®µè¯»å–ï¼Œä¸å†ä»ç¯å¢ƒå˜é‡è¯»å–
            # å¦‚æœç”¨æˆ·é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰ category_idï¼Œåˆ™ä½¿ç”¨é»˜è®¤å€¼
            'arxiv_categories': ['cs.CV', 'cs.LG'],  # é»˜è®¤å€¼ï¼Œä¼šè¢« _load_user_categories() è¦†ç›–
            'max_entries': get_int('MAX_ENTRIES', 50),
            'num_brief_papers': get_int('NUM_BRIEF_PAPERS', 7),
            'num_detailed_papers': get_int('NUM_DETAILED_PAPERS', 3),
            # ç›¸å…³æ€§è¿‡æ»¤é˜ˆå€¼ï¼ˆç”¨äºå‰”é™¤ä½åˆ†é¡¹ï¼‰
            'relevance_filter_threshold': get_int('RELEVANCE_FILTER_THRESHOLD', 6),
            
            # LLMé…ç½®

            'qwen_model_temperature': get_float('QWEN_MODEL_TEMPERATURE', 0.7),
            'qwen_model_top_p': get_float('QWEN_MODEL_TOP_P', 0.9),
            'qwen_model_max_tokens': get_int('QWEN_MODEL_MAX_TOKENS', 4000),
            'qwen_model_light_temperature': get_float('QWEN_MODEL_LIGHT_TEMPERATURE', 0.5),
            'qwen_model_light_top_p': get_float('QWEN_MODEL_LIGHT_TOP_P', 0.8),
            'qwen_model_light_max_tokens': get_int('QWEN_MODEL_LIGHT_MAX_TOKENS', 2000),
            'max_workers': get_int('MAX_WORKERS', 5),
            
            # æ–‡ä»¶è·¯å¾„é…ç½®
            'user_categories_file': get_str('USER_CATEGORIES_FILE', 'data/users/user_categories.json'),
            'save_directory': get_str('SAVE_DIRECTORY', 'arxiv_history'),
            'save_markdown': get_bool('SAVE_MARKDOWN', True),
            
            # é‚®ä»¶é…ç½®
            'send_email': get_bool('SEND_EMAIL', False),
            'sender_email': get_str('SENDER_EMAIL', ''),
            'receiver_email': get_str('RECEIVER_EMAIL', ''),
            'email_password': get_str('EMAIL_PASSWORD', ''),
            'smtp_server': get_str('SMTP_SERVER', ''),
            'smtp_port': get_int('SMTP_PORT', 587),
            'use_ssl': get_bool('USE_SSL', False),
            'use_tls': get_bool('USE_TLS', True),
            'subject_prefix': get_str('SUBJECT_PREFIX', 'æ¯æ—¥arXiv'),
            
            # æ—¶åŒºå’Œæ ¼å¼é…ç½®
            'timezone': get_str('TIMEZONE', 'Asia/Shanghai'),
            'date_format': get_str('DATE_FORMAT', '%Y-%m-%d'),
            'time_format': get_str('TIME_FORMAT', '%H:%M:%S'),
            
            # æ—¥å¿—é…ç½®ï¼ˆç®€åŒ–ï¼šåªä¿ç•™ç”¨æˆ·å¯é…ç½®çš„3é¡¹ï¼‰
            'log_level': 'DEBUG',  # å›ºå®šä¸ºDEBUGï¼Œä¸å†å¯é…ç½®
            'log_file': 'logs/arxiv_recommender.log',  # å›ºå®šè·¯å¾„ï¼Œä¸å†å¯é…ç½®
            'log_to_console': get_bool('LOG_TO_CONSOLE', True),
            'log_max_size': get_int('LOG_MAX_SIZE', 10),
            'log_backup_count': get_int('LOG_BACKUP_COUNT', 5),
        }
        
        return config
    
    def _get_current_username(self) -> str:
        """è·å–å½“å‰ç”¨æˆ·åã€‚
        
        Returns:
            ç”¨æˆ·åå­—ç¬¦ä¸²ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›é»˜è®¤å€¼"TEST"
        """
        if self.username:
            return self.username
        
        # ä»ç”¨æˆ·é…ç½®æ–‡ä»¶ä¸­è·å–ç”¨æˆ·å
        categories_file = self.config['user_categories_file']
        try:
            if os.path.exists(categories_file):
                with open(categories_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                if isinstance(data, list) and len(data) > 0:
                    first_user = data[0]
                    if isinstance(first_user, dict) and 'username' in first_user:
                        return first_user['username']
        except Exception as e:
            logger.warning(f"è·å–ç”¨æˆ·åå¤±è´¥: {e}")
        
        return "TEST"  # é»˜è®¤ç”¨æˆ·å
    
    def _load_user_categories(self):
        """ä»ç”¨æˆ·åˆ†ç±»JSONæ–‡ä»¶åŠ è½½åˆ†ç±»æ ‡ç­¾ï¼Œæ›´æ–°é…ç½®ã€‚"""
        categories_file = self.config['user_categories_file']
        logger.debug(f"å°è¯•åŠ è½½ç”¨æˆ·åˆ†ç±»æ–‡ä»¶: {categories_file}")
        
        try:
            if os.path.exists(categories_file):
                with open(categories_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # æ£€æŸ¥æ•°æ®æ ¼å¼
                if isinstance(data, list) and len(data) > 0:
                    target_user = None
                    
                    # æ ¹æ®usernameæŸ¥æ‰¾å¯¹åº”ç”¨æˆ·ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªç”¨æˆ·
                    if self.username:
                        # æŸ¥æ‰¾æŒ‡å®šç”¨æˆ·åçš„é…ç½®
                        for user in data:
                            if isinstance(user, dict) and user.get('username') == self.username:
                                target_user = user
                                logger.debug(f"æ‰¾åˆ°æŒ‡å®šç”¨æˆ·é…ç½®: {self.username}")
                                break
                        
                        if not target_user:
                            logger.warning(f"æœªæ‰¾åˆ°ç”¨æˆ· {self.username} çš„é…ç½®ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç”¨æˆ·é…ç½®")
                            target_user = data[0] if isinstance(data[0], dict) else None
                    else:
                        # æ²¡æœ‰æŒ‡å®šç”¨æˆ·åï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç”¨æˆ·
                        target_user = data[0] if isinstance(data[0], dict) else None
                        logger.debug("æœªæŒ‡å®šç”¨æˆ·åï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç”¨æˆ·é…ç½®")
                    
                    if target_user and isinstance(target_user, dict):
                        # å¤„ç†category_idå­—æ®µï¼Œæ›´æ–°arxiv_categoriesé…ç½®
                        if 'category_id' in target_user and target_user['category_id']:
                            category_str = target_user['category_id'].strip()
                            if category_str:
                                # è§£æå¤šä¸ªåˆ†ç±»æ ‡ç­¾
                                categories = [cat.strip() for cat in category_str.split(',') if cat.strip()]
                                if categories:
                                    self.config['arxiv_categories'] = categories
                                    username_info = f"ç”¨æˆ· {target_user.get('username', 'æœªçŸ¥')}" if target_user.get('username') else "ç¬¬ä¸€ä¸ªç”¨æˆ·"
                                    logger.success(f"ä»JSONæ–‡ä»¶åŠ è½½{username_info}çš„åˆ†ç±»æ ‡ç­¾: {categories}")
                                    return
                                else:
                                    logger.warning(f"category_idå­—æ®µä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®: {category_str}")
                            else:
                                logger.warning("category_idå­—æ®µä¸ºç©ºå­—ç¬¦ä¸²")
                        else:
                            logger.debug("JSONæ–‡ä»¶ä¸­æœªæ‰¾åˆ°category_idå­—æ®µï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®")
                    else:
                        logger.warning(f"ç›®æ ‡ç”¨æˆ·æ•°æ®æ ¼å¼ä¸æ­£ç¡®: {categories_file}")
                else:
                    logger.warning(f"JSONæ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®: {categories_file}")
            else:
                logger.warning(f"ç”¨æˆ·åˆ†ç±»æ–‡ä»¶ä¸å­˜åœ¨: {categories_file}")
                
        except json.JSONDecodeError as e:
            logger.error(f"JSONæ–‡ä»¶è§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®")
        except Exception as e:
            logger.error(f"ç”¨æˆ·åˆ†ç±»æ–‡ä»¶è¯»å–å¤±è´¥: {e}ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®")
        
        # å¦‚æœæ²¡æœ‰æˆåŠŸåŠ è½½ï¼Œä¿æŒç¯å¢ƒå˜é‡é…ç½®
        logger.debug(f"ä½¿ç”¨ç¯å¢ƒå˜é‡åˆ†ç±»æ ‡ç­¾: {self.config['arxiv_categories']}")
    
    def load_research_interests_from_file(self):
        """ä»æ–‡ä»¶åŠ è½½ç ”ç©¶å…´è¶£ï¼ˆç”¨äºStreamlitç•Œé¢ï¼‰
        
        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            interests_file = project_root / "research_interests.md"
            if interests_file.exists():
                with open(interests_file, 'r', encoding='utf-8') as f:
                    self.research_interests = [line.strip() for line in f if line.strip()]
                logger.success(f"ä»æ–‡ä»¶åŠ è½½ç ”ç©¶å…´è¶£: {len(self.research_interests)} æ¡")
            else:
                logger.warning("ç ”ç©¶å…´è¶£æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç©ºåˆ—è¡¨")
                self.research_interests = []
            return True
        except Exception as e:
            logger.error(f"ç ”ç©¶å…´è¶£åŠ è½½å¤±è´¥: {str(e)}")
            self.research_interests = []
            return False
    
    def load_user_profiles(self):
        """åŠ è½½ç”¨æˆ·é…ç½®ï¼ˆç”¨äºStreamlitç•Œé¢ï¼‰
        
        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            user_profiles_file = project_root / "data" / "users" / "user_categories.json"
            if user_profiles_file.exists():
                with open(user_profiles_file, 'r', encoding='utf-8') as f:
                    self.user_profiles = json.load(f)
                logger.success(f"åŠ è½½ç”¨æˆ·é…ç½®: {len(self.user_profiles)} ä¸ªç”¨æˆ·")
            else:
                logger.warning("ç”¨æˆ·é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç©ºåˆ—è¡¨")
                self.user_profiles = []
            return True
        except Exception as e:
            logger.error(f"ç”¨æˆ·é…ç½®åŠ è½½å¤±è´¥: {str(e)}")
            self.user_profiles = []
            return False
    
    def get_config(self):
        """è·å–å½“å‰é…ç½®ï¼ˆç”¨äºStreamlitç•Œé¢ï¼‰
        
        Returns:
            dict: å½“å‰é…ç½®å­—å…¸
        """
        return self.config.copy()
    
    def get_research_interests(self):
        """è·å–ç ”ç©¶å…´è¶£åˆ—è¡¨ï¼ˆç”¨äºStreamlitç•Œé¢ï¼‰
        
        Returns:
            list: ç ”ç©¶å…´è¶£åˆ—è¡¨
        """
        return self.research_interests.copy()
    
    def get_user_profiles(self):
        """è·å–ç”¨æˆ·é…ç½®åˆ—è¡¨ï¼ˆç”¨äºStreamlitç•Œé¢ï¼‰
        
        Returns:
            list: ç”¨æˆ·é…ç½®åˆ—è¡¨
        """
        return self.user_profiles.copy()
    
    def update_research_interests(self, interests):
        """æ›´æ–°ç ”ç©¶å…´è¶£ï¼ˆç”¨äºStreamlitç•Œé¢ï¼‰
        
        Args:
            interests: ç ”ç©¶å…´è¶£åˆ—è¡¨æˆ–å­—ç¬¦ä¸²
        """
        if isinstance(interests, str):
            self.research_interests = [line.strip() for line in interests.split('\n') if line.strip()]
        elif isinstance(interests, list):
            self.research_interests = interests
        else:
            logger.warning(f"æ— æ•ˆçš„ç ”ç©¶å…´è¶£æ ¼å¼: {type(interests)}")
        
        logger.debug(f"æ›´æ–°ç ”ç©¶å…´è¶£: {len(self.research_interests)} æ¡")
    
    def set_task_id(self, task_id: str):
        """è®¾ç½®å½“å‰ä»»åŠ¡IDï¼ˆç”¨äºè¿›åº¦æ›´æ–°ï¼‰
        
        Args:
            task_id: ä»»åŠ¡ID
        """
        self.task_id = task_id
        logger.debug(f"è®¾ç½®ä»»åŠ¡ID: {task_id}")
    
    # è¿›åº¦æ›´æ–°æ–¹æ³•å·²ä» ProgressTracker ç»§æ‰¿
    
    def run_debug_mode(self, target_date=None):
        """è¿è¡Œè°ƒè¯•æ¨¡å¼ï¼ˆç”¨äºStreamlitç•Œé¢ï¼‰
        
        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼Œæ ¼å¼ä¸ºYYYY-MM-DDï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ä»Šå¤©
            
        Returns:
            tuple: (success, result_data, error_message)
        """
        try:
            import time
            import random
            from datetime import datetime
            
            if target_date is None:
                target_date = format_timezone_date()
            
            logger.info(f"ğŸ”§ è°ƒè¯•æ¨¡å¼å¯åŠ¨ - ç›®æ ‡æ—¥æœŸ: {target_date}")
            
            # æ¨¡æ‹Ÿè·å–è®ºæ–‡
            logger.info("ğŸ“š æ¨¡æ‹Ÿè·å–ArXivè®ºæ–‡...")
            time.sleep(1)
            
            # ç”Ÿæˆå‡æ•°æ®
            fake_papers = [
                {
                    "title": "Advanced Machine Learning Techniques for Natural Language Processing",
                    "authors": ["John Smith", "Jane Doe"],
                    "abstract": "This paper presents novel approaches to natural language processing using advanced machine learning techniques...",
                    "arxiv_id": "2024.0001",
                    "categories": ["cs.CL", "cs.LG"],
                    "published": target_date
                },
                {
                    "title": "Quantum Computing Applications in Cryptography",
                    "authors": ["Alice Johnson", "Bob Wilson"],
                    "abstract": "We explore the implications of quantum computing on modern cryptographic systems...",
                    "arxiv_id": "2024.0002",
                    "categories": ["quant-ph", "cs.CR"],
                    "published": target_date
                }
            ]
            
            logger.success(f"âœ… æ¨¡æ‹Ÿè·å–åˆ° {len(fake_papers)} ç¯‡è®ºæ–‡")
            
            # æ¨¡æ‹ŸLLMåˆ†æ
            logger.info("ğŸ¤– æ¨¡æ‹ŸLLMåˆ†æå¤„ç†...")
            time.sleep(2)
            
            # ç”Ÿæˆå‡çš„æŠ¥å‘Šå†…å®¹
            fake_summary = f"""# ArXiv æ¯æ—¥è®ºæ–‡æ¨èæŠ¥å‘Š

**æ—¥æœŸ**: {target_date}
**ç”Ÿæˆæ—¶é—´**: {get_timezone_aware_now().strftime('%Y-%m-%d %H:%M:%S')}
**æ¨¡å¼**: è°ƒè¯•æ¨¡å¼ ğŸ”§

## ğŸ“Š ä»Šæ—¥æ¦‚è§ˆ

- **è®ºæ–‡æ€»æ•°**: {len(fake_papers)}
- **é‡ç‚¹æ¨è**: 2ç¯‡
- **æ¶‰åŠé¢†åŸŸ**: æœºå™¨å­¦ä¹ ã€é‡å­è®¡ç®—ã€å¯†ç å­¦

## ğŸ¯ é‡ç‚¹æ¨èè®ºæ–‡

### 1. Advanced Machine Learning Techniques for Natural Language Processing

**ä½œè€…**: John Smith, Jane Doe  
**ArXiv ID**: 2024.0001  
**åˆ†ç±»**: cs.CL, cs.LG

**æ¨èç†ç”±**: è¿™ç¯‡è®ºæ–‡æå‡ºäº†åˆ›æ–°çš„è‡ªç„¶è¯­è¨€å¤„ç†æ–¹æ³•ï¼Œç»“åˆäº†æœ€æ–°çš„æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œå¯¹å½“å‰NLPé¢†åŸŸå…·æœ‰é‡è¦æ„ä¹‰ã€‚

**æ ¸å¿ƒè´¡çŒ®**:
- æå‡ºäº†æ–°çš„æ³¨æ„åŠ›æœºåˆ¶
- åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†SOTAç»“æœ
- æ–¹æ³•å…·æœ‰è‰¯å¥½çš„å¯è§£é‡Šæ€§

### 2. Quantum Computing Applications in Cryptography

**ä½œè€…**: Alice Johnson, Bob Wilson  
**ArXiv ID**: 2024.0002  
**åˆ†ç±»**: quant-ph, cs.CR

**æ¨èç†ç”±**: æ¢è®¨äº†é‡å­è®¡ç®—å¯¹ç°ä»£å¯†ç å­¦çš„å½±å“ï¼Œä¸ºåé‡å­å¯†ç å­¦çš„å‘å±•æä¾›äº†é‡è¦è§è§£ã€‚

**æ ¸å¿ƒè´¡çŒ®**:
- åˆ†æäº†é‡å­ç®—æ³•å¯¹RSAåŠ å¯†çš„å¨èƒ
- æå‡ºäº†æŠ—é‡å­æ”»å‡»çš„æ–°æ–¹æ¡ˆ
- ç»™å‡ºäº†å®ç”¨çš„å®‰å…¨å»ºè®®

## ğŸ“ˆ æŠ€æœ¯è¶‹åŠ¿åˆ†æ

æœ¬æ—¥è®ºæ–‡åæ˜ å‡ºä»¥ä¸‹æŠ€æœ¯è¶‹åŠ¿ï¼š
1. **æœºå™¨å­¦ä¹ ä¸NLPçš„æ·±åº¦èåˆ**: è¶Šæ¥è¶Šå¤šçš„ç ”ç©¶å…³æ³¨å¦‚ä½•å°†å…ˆè¿›çš„MLæŠ€æœ¯åº”ç”¨åˆ°NLPä»»åŠ¡ä¸­
2. **é‡å­è®¡ç®—çš„å®ç”¨åŒ–**: é‡å­è®¡ç®—æ­£ä»ç†è®ºç ”ç©¶å‘å®é™…åº”ç”¨è½¬å˜
3. **å®‰å…¨æ€§è€ƒé‡**: éšç€æ–°æŠ€æœ¯çš„å‘å±•ï¼Œå®‰å…¨æ€§é—®é¢˜å˜å¾—è¶Šæ¥è¶Šé‡è¦

---
*æœ¬æŠ¥å‘Šç”±ArXivæ¯æ—¥è®ºæ–‡æ¨èç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""
            
            fake_detailed_analysis = "è¯¦ç»†åˆ†æå†…å®¹...(è°ƒè¯•æ¨¡å¼ç”Ÿæˆ)"
            fake_brief_analysis = "ç®€è¦åˆ†æå†…å®¹...(è°ƒè¯•æ¨¡å¼ç”Ÿæˆ)"
            
            logger.success("âœ… æ¨¡æ‹Ÿåˆ†æå®Œæˆ")
            
            # ä¿å­˜æŠ¥å‘Š
            logger.info("ğŸ’¾ ä¿å­˜è°ƒè¯•æŠ¥å‘Š...")
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = project_root / "output" / "reports"
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜Markdownæ–‡ä»¶
            md_filename = f"arxiv_recommendation_{target_date}_debug.md"
            md_filepath = output_dir / md_filename
            
            with open(md_filepath, 'w', encoding='utf-8') as f:
                f.write(fake_summary)
            
            # ä¿å­˜HTMLæ–‡ä»¶
            html_filename = f"arxiv_recommendation_{target_date}_debug.html"
            html_filepath = output_dir / html_filename
            
            html_content = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>ArXiv æ¯æ—¥è®ºæ–‡æ¨è - {target_date} (è°ƒè¯•æ¨¡å¼)</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }}
        h1, h2, h3 {{ color: #333; }}
        .debug-badge {{ background: #ff6b6b; color: white; padding: 4px 8px; border-radius: 4px; font-size: 12px; }}
    </style>
</head>
<body>
    <div class="debug-badge">è°ƒè¯•æ¨¡å¼</div>
    <h1>ArXiv æ¯æ—¥è®ºæ–‡æ¨èæŠ¥å‘Š</h1>
    <p><strong>æ—¥æœŸ</strong>: {target_date}</p>
    <p><strong>ç”Ÿæˆæ—¶é—´</strong>: {get_timezone_aware_now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    <p>è¿™æ˜¯è°ƒè¯•æ¨¡å¼ç”Ÿæˆçš„ç¤ºä¾‹æŠ¥å‘Šã€‚</p>
</body>
</html>"""
            
            with open(html_filepath, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            logger.success(f"âœ… è°ƒè¯•æŠ¥å‘Šå·²ä¿å­˜: {md_filename}")
            
            result_data = {
                'summary': fake_summary,
                'detailed_analysis': fake_detailed_analysis,
                'brief_analysis': fake_brief_analysis,
                'papers_count': len(fake_papers),
                'md_file': str(md_filepath),
                'html_file': str(html_filepath),
                'target_date': target_date
            }
            
            return True, result_data, None
            
        except Exception as e:
            error_msg = f"è°ƒè¯•æ¨¡å¼è¿è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return False, None, error_msg
    
    def setup_realtime_logging(self):
        """è®¾ç½®å®æ—¶æ—¥å¿—ï¼ˆç”¨äºStreamlitç•Œé¢ï¼‰
        
        Returns:
            bool: è®¾ç½®æ˜¯å¦æˆåŠŸ
        """
        try:
            # è¿™é‡Œå¯ä»¥æ·»åŠ ç‰¹å®šçš„æ—¥å¿—é…ç½®
            # ç›®å‰ä½¿ç”¨é»˜è®¤çš„loggeré…ç½®
            logger.info("å®æ—¶æ—¥å¿—å·²è®¾ç½®")
            return True
        except Exception as e:
            logger.error(f"å®æ—¶æ—¥å¿—è®¾ç½®å¤±è´¥: {str(e)}")
            return False
    
    def get_recent_reports(self, limit=None, username_filter=None):
        """è·å–æœ€è¿‘çš„æŠ¥å‘Šæ–‡ä»¶ï¼ˆç”¨äºStreamlitç•Œé¢ï¼‰
        
        Args:
            limit: è¿”å›çš„æŠ¥å‘Šæ•°é‡é™åˆ¶ï¼Œå¦‚æœä¸º None åˆ™ä¸é™åˆ¶æ•°é‡
            username_filter: å¯é€‰çš„ç”¨æˆ·åç­›é€‰ï¼Œå¦‚æœæä¾›åˆ™åªè¿”å›åŒ¹é…çš„æŠ¥å‘Š
            
        Returns:
            list: æŠ¥å‘Šæ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
        """
        try:
            # ä½¿ç”¨ä¸ä¿å­˜ä¸€è‡´çš„ç›®å½•ï¼šæ¥è‡ªé…ç½® SAVE_DIRECTORY
            save_dir = self.config.get('save_directory', 'arxiv_history')
            reports_dir = Path(save_dir)
            if not reports_dir.is_absolute():
                reports_dir = project_root / reports_dir
            
            if not reports_dir.exists():
                return []
            
            # è·å–æ‰€æœ‰markdownæŠ¥å‘Šæ–‡ä»¶
            report_files = list(reports_dir.glob("*.md"))
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
            report_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            # æ„å»ºæŠ¥å‘Šä¿¡æ¯
            reports = []
            for file_path in report_files:
                try:
                    stat = file_path.stat()
                    # æ–‡ä»¶åæ ¼å¼ï¼šYYYY-MM-DD_{username}_ARXIV_summary.md
                    # æå–ç”¨æˆ·åï¼šæŒ‰ _ åˆ†å‰²ï¼Œå–ç´¢å¼•1çš„éƒ¨åˆ†ï¼ˆç´¢å¼•0æ˜¯æ—¥æœŸï¼‰
                    stem_parts = file_path.stem.split('_')
                    date_str = stem_parts[0] if len(stem_parts) > 0 else 'unknown'
                    
                    # æå–ç”¨æˆ·åï¼šæ‰¾åˆ° "ARXIV" çš„ä½ç½®ï¼Œç”¨æˆ·ååœ¨æ—¥æœŸå’ŒARXIVä¹‹é—´
                    username = None
                    if len(stem_parts) >= 3:
                        # æŸ¥æ‰¾ "ARXIV" çš„ä½ç½®
                        arxiv_index = None
                        for i, part in enumerate(stem_parts):
                            if part.upper() == 'ARXIV':
                                arxiv_index = i
                                break
                        
                        if arxiv_index and arxiv_index > 1:
                            # ç”¨æˆ·åæ˜¯ç´¢å¼•1åˆ°arxiv_index-1ä¹‹é—´çš„æ‰€æœ‰éƒ¨åˆ†ï¼Œç”¨ä¸‹åˆ’çº¿è¿æ¥
                            username_parts = stem_parts[1:arxiv_index]
                            username = '_'.join(username_parts)
                        elif len(stem_parts) >= 2:
                            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ARXIVï¼Œå‡è®¾ç¬¬äºŒä¸ªç‰‡æ®µæ˜¯ç”¨æˆ·åï¼ˆå‘åå…¼å®¹ï¼‰
                            username = stem_parts[1]
                    
                    # å¦‚æœæä¾›äº†ç”¨æˆ·åç­›é€‰ï¼Œåªè¿”å›åŒ¹é…çš„æŠ¥å‘Š
                    if username_filter and username != username_filter:
                        continue
                    
                    reports.append({
                        'filename': file_path.name,
                        'name': file_path.name,
                        'filepath': str(file_path),
                        'path': file_path,
                        'size': stat.st_size,
                        'modified_time': stat.st_mtime,
                        'date': date_str,
                        'username': username  # æ·»åŠ ç”¨æˆ·åå­—æ®µ
                    })
                except Exception as e:
                    logger.warning(f"æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯ {file_path}: {str(e)}")
                    continue
            
            # é™åˆ¶æ•°é‡ï¼ˆåœ¨ç­›é€‰åï¼‰ï¼Œåªæœ‰å½“ limit ä¸ä¸º None æ—¶æ‰é™åˆ¶
            if limit is not None:
                reports = reports[:limit]
            
            return reports
            
        except Exception as e:
            logger.error(f"è·å–æœ€è¿‘æŠ¥å‘Šå¤±è´¥: {str(e)}")
            return []
    
    def run_full_recommendation(self, specific_date=None):
        """è¿è¡Œå®Œæ•´çš„æ¨èæµç¨‹ï¼ˆè·å–æ¨è + ä¿å­˜æŠ¥å‘Šï¼‰
        
        Args:
            specific_date: æŒ‡å®šæ—¥æœŸï¼Œæ ¼å¼ä¸ºYYYY-MM-DD
            
        Returns:
            tuple: (success, result_data, error_msg)
        """
        try:
            # æ›´æ–°è¿›åº¦ï¼šåˆå§‹åŒ–ç»„ä»¶
            self._update_progress(
                step="åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...",
                percentage=5,
                log_message="æ­£åœ¨åˆå§‹åŒ–ArXivè·å–å™¨å’ŒLLMæä¾›å•†"
            )
            
            # è·å–æ¨èç»“æœ
            self._update_progress(
                step="è·å–è®ºæ–‡æ¨è...",
                percentage=10,
                log_message="å¼€å§‹è·å–æ¨èç»“æœ"
            )
            
            cli_result = self.get_recommendations(specific_date=specific_date)
            
            if not cli_result['success']:
                self._update_progress(
                    step="æ¨èå¤±è´¥",
                    percentage=0,
                    log_message=f"æ¨èå¤±è´¥: {cli_result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                    log_level="error"
                )
                return False, cli_result.get('data'), cli_result.get('error', 'æœªçŸ¥é”™è¯¯')
            
            # è·å–æ¨èæ•°æ®
            report_data = cli_result['data']
            target_date = cli_result['target_date']
            current_time = cli_result['current_time']
            
            # ä¿å­˜æŠ¥å‘Š
            self._update_progress(
                step="ä¿å­˜æŠ¥å‘Š...",
                percentage=70,
                log_message="æ­£åœ¨ç”Ÿæˆå¹¶ä¿å­˜æ¨èæŠ¥å‘Š"
            )
            
            save_result = self.save_reports(report_data, current_time, target_date=target_date)
            
            # è·å–åˆ†ç¦»çš„å†…å®¹
            summary_content = report_data.get('summary', '')
            detailed_analysis = report_data.get('detailed_analysis', '')
            brief_analysis = report_data.get('brief_analysis', '')
            
            # åˆå¹¶å†…å®¹
            markdown_content = summary_content + detailed_analysis + brief_analysis
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = get_timezone_aware_now().strftime("%Y%m%d_%H%M%S")
            filename = f"arxiv_recommendations_{timestamp}.md"
            
            result_data = {
                'markdown_content': markdown_content,
                'summary_content': summary_content,
                'detailed_analysis': detailed_analysis,
                'brief_analysis': brief_analysis,
                'html_content': save_result.get('html_content'),
                'html_filepath': save_result.get('html_filepath'),
                'filename': filename,
                'target_date': target_date
            }
            
            # å®Œæˆ
            self._update_progress(
                step="æ¨èå®Œæˆ",
                percentage=100,
                log_message=f"æ¨èæŠ¥å‘Šå·²ç”Ÿæˆ: {filename}"
            )
            
            return True, result_data, None
            
        except Exception as e:
            logger.error(f"å®Œæ•´æ¨èæµç¨‹å¤±è´¥: {str(e)}")
            self._update_progress(
                step="æ¨èå¤±è´¥",
                percentage=0,
                log_message=f"å®Œæ•´æ¨èæµç¨‹å¤±è´¥: {str(e)}",
                log_level="error"
            )
            return False, None, f"å®Œæ•´æ¨èæµç¨‹å¤±è´¥: {str(e)}"
    
    def _initialize_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶ã€‚"""
        logger.info("ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–å¼€å§‹")
        try:
            # åˆå§‹åŒ–ArXivè·å–å™¨
            logger.debug("åˆå§‹åŒ–ArXivè·å–å™¨")
            self.arxiv_fetcher = ArxivFetcher(
                base_url=self.config['arxiv_base_url'],
                retries=self.config['arxiv_retries'],
                delay=self.config['arxiv_delay']
            )
            logger.debug(f"ArXivè·å–å™¨åˆå§‹åŒ–å®Œæˆ - URL: {self.config['arxiv_base_url']}, é‡è¯•: {self.config['arxiv_retries']}, å»¶è¿Ÿ: {self.config['arxiv_delay']}s")
            
            # åˆå§‹åŒ–LLMæä¾›å•†ï¼ˆç»Ÿä¸€ä½¿ç”¨ DashScope/Qwenï¼‰
            heavy_model = get_str('QWEN_MODEL', self.config['qwen_model'])
            heavy_base_url = get_str('DASHSCOPE_BASE_URL', self.config['dashscope_base_url'])
            heavy_api_key = get_str('DASHSCOPE_API_KEY', self.config['dashscope_api_key'])
            heavy_temperature = self.config['qwen_model_temperature']
            heavy_top_p = self.config['qwen_model_top_p']
            heavy_max_tokens = self.config['qwen_model_max_tokens']

            logger.debug(f"åˆå§‹åŒ–LLMæä¾›å•† - æä¾›æ–¹: dashscope, æ¨¡å‹: {heavy_model}")
            # æ„é€ ä¸»LLMæä¾›è€…ï¼Œå¹¶ä½œä¸ºä¾èµ–æ³¨å…¥ä¼ é€’ç»™æ¨èå¼•æ“
            # LLMProvider çš„ description å‚æ•°ä»ç„¶æ˜¯å­—ç¬¦ä¸²ï¼Œæå– positive_query
            research_interests_dict = self._load_research_interests()
            description_str = research_interests_dict.get("positive_query", "") if isinstance(research_interests_dict, dict) else str(research_interests_dict)
            self.llm_provider = LLMProvider(
                model=heavy_model,
                base_url=heavy_base_url,
                api_key=heavy_api_key,
                description=description_str,
                username=self._get_current_username(),
                temperature=heavy_temperature,
                top_p=heavy_top_p,
                max_tokens=heavy_max_tokens,
            )
            logger.debug("LLMæä¾›å•†åˆå§‹åŒ–å®Œæˆ")
            
            # åˆå§‹åŒ–æ¨èå¼•æ“
            logger.debug("åˆå§‹åŒ–æ¨èå¼•æ“")
            research_interests = self._load_research_interests()
            
            # è·å–ç”¨æˆ·åï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä»ç”¨æˆ·é…ç½®ä¸­è·å–
            username = self._get_current_username()
            
            self.recommendation_engine = RecommendationEngine(
                categories=self.config['arxiv_categories'],
                max_entries=self.config['max_entries'],
                num_brief_papers=self.config['num_brief_papers'],
                num_detailed_papers=self.config['num_detailed_papers'],
                relevance_filter_threshold=self.config.get('relevance_filter_threshold', 6),
                model=heavy_model,
                base_url=heavy_base_url,
                api_key=heavy_api_key,
                description=research_interests,
                username=username,
                num_workers=self.config['max_workers'],
                temperature=heavy_temperature,
                top_p=heavy_top_p,
                max_tokens=heavy_max_tokens,
                arxiv_fetcher=self.arxiv_fetcher,
                llm_provider=self.llm_provider,
                task_id=self.task_id,  # ä¼ é€’task_idç”¨äºè¿›åº¦æ›´æ–°
            )
            logger.debug(f"æ¨èå¼•æ“åˆå§‹åŒ–å®Œæˆ - ç±»åˆ«: {self.config['arxiv_categories']}, å·¥ä½œçº¿ç¨‹: {self.config['max_workers']}")
            
            # åˆå§‹åŒ–è¾“å‡ºç®¡ç†å™¨
            logger.debug("åˆå§‹åŒ–è¾“å‡ºç®¡ç†å™¨")
            template_dir = project_root / 'config' / 'templates'
            self.output_manager = OutputManager(str(template_dir))
            logger.debug("è¾“å‡ºç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
            logger.success("ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _load_research_interests(self) -> Dict[str, str]:
        """ä»ç”¨æˆ·åˆ†ç±»JSONæ–‡ä»¶åŠ è½½ç ”ç©¶å…´è¶£ã€‚
        
        Returns:
            ç ”ç©¶å…´è¶£å­—å…¸ï¼ŒåŒ…å« positive_query å’Œ negative_query
        """
        categories_file = self.config['user_categories_file']
        logger.debug(f"å°è¯•åŠ è½½ç ”ç©¶å…´è¶£æ–‡ä»¶: {categories_file}")
        
        try:
            if os.path.exists(categories_file):
                with open(categories_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # æ£€æŸ¥æ•°æ®æ ¼å¼
                if isinstance(data, list) and len(data) > 0:
                    target_user = None
                    
                    # æ ¹æ®usernameæŸ¥æ‰¾å¯¹åº”ç”¨æˆ·ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªç”¨æˆ·
                    if self.username:
                        # æŸ¥æ‰¾æŒ‡å®šç”¨æˆ·åçš„é…ç½®
                        for user in data:
                            if isinstance(user, dict) and user.get('username') == self.username:
                                target_user = user
                                logger.debug(f"æ‰¾åˆ°æŒ‡å®šç”¨æˆ·çš„ç ”ç©¶å…´è¶£: {self.username}")
                                break
                        
                        if not target_user:
                            logger.warning(f"æœªæ‰¾åˆ°ç”¨æˆ· {self.username} çš„ç ”ç©¶å…´è¶£ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç”¨æˆ·é…ç½®")
                            target_user = data[0] if isinstance(data[0], dict) else None
                    else:
                        # æ²¡æœ‰æŒ‡å®šç”¨æˆ·åï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç”¨æˆ·
                        target_user = data[0] if isinstance(data[0], dict) else None
                        logger.debug("æœªæŒ‡å®šç”¨æˆ·åï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç”¨æˆ·çš„ç ”ç©¶å…´è¶£")
                    
                    if target_user and isinstance(target_user, dict):
                        # å¤„ç†user_inputå’Œnegative_queryå­—æ®µ
                        positive_query = target_user.get('user_input', '')
                        negative_query = target_user.get('negative_query', '')  # å¯é€‰å­—æ®µï¼Œé»˜è®¤ä¸ºç©º
                        
                        if positive_query:
                            description_dict = {
                                "positive_query": positive_query,
                                "negative_query": negative_query
                            }
                            username_info = f"ç”¨æˆ· {target_user.get('username', 'æœªçŸ¥')}" if target_user.get('username') else "ç¬¬ä¸€ä¸ªç”¨æˆ·"
                            logger.success(f"ä»JSONæ–‡ä»¶åŠ è½½{username_info}çš„ç ”ç©¶å…´è¶£: {categories_file}")
                            return description_dict
                        else:
                            logger.warning(f"ç›®æ ‡ç”¨æˆ·ç¼ºå°‘user_inputå­—æ®µ: {categories_file}")
                    else:
                        logger.warning(f"ç›®æ ‡ç”¨æˆ·æ•°æ®æ ¼å¼ä¸æ­£ç¡®: {categories_file}")
                else:
                    logger.warning(f"JSONæ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®: {categories_file}")
            else:
                logger.warning(f"ç”¨æˆ·åˆ†ç±»æ–‡ä»¶ä¸å­˜åœ¨: {categories_file}")
                
        except json.JSONDecodeError as e:
            logger.error(f"JSONæ–‡ä»¶è§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        except Exception as e:
            logger.error(f"ç”¨æˆ·åˆ†ç±»æ–‡ä»¶è¯»å–å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        
        # å›é€€åˆ°é»˜è®¤é…ç½®
        logger.info("ä½¿ç”¨é»˜è®¤ç ”ç©¶å…´è¶£é…ç½®")
        return {
            "positive_query": "æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†",
            "negative_query": ""
        }
    
    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´ã€‚
        
        Returns:
            æ ¼å¼åŒ–çš„å½“å‰æ—¶é—´å­—ç¬¦ä¸²
        """
        logger.debug("è·å–å½“å‰æ—¶é—´")
        try:
            # å°è¯•é€šè¿‡LLMå·¥å…·è·å–æ—¶é—´
            current_time = get_current_time()
            if current_time:
                logger.debug(f"LLMæ—¶é—´æœåŠ¡è·å–æˆåŠŸ: {current_time}")
                return current_time
        except Exception as e:
            logger.warning(f"LLMæ—¶é—´æœåŠ¡å¤±è´¥ï¼Œå›é€€åˆ°æœ¬åœ°æ—¶é—´: {e}")
        
        # å›é€€åˆ°æœ¬åœ°æ—¶é—´
        local_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        logger.debug(f"ä½¿ç”¨æœ¬åœ°æ—¶é—´: {local_time}")
        return local_time
    
    def _send_email_if_configured(self, html_content: str):
        """å¦‚æœé…ç½®äº†é‚®ä»¶ï¼Œåˆ™å‘é€é‚®ä»¶ã€‚
        
        Args:
            html_content: é¢„å¤„ç†çš„HTMLå†…å®¹
        """
        logger.debug("æ£€æŸ¥é‚®ä»¶å‘é€é…ç½®")
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å¯ç”¨é‚®ä»¶å‘é€
        if not self.config['send_email']:
            logger.debug("é‚®ä»¶å‘é€å·²ç¦ç”¨")
            return
            
        if not all([
            self.config['sender_email'],
            self.config['receiver_email'],
            self.config['email_password'],
            self.config['smtp_server']
        ]):
            logger.warning("é‚®ä»¶é…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡å‘é€")
            return
        
        # å¦‚æœæ²¡æœ‰HTMLå†…å®¹ï¼Œè·³è¿‡å‘é€
        if not html_content:
            logger.warning("HTMLå†…å®¹ä¸ºç©ºï¼Œè·³è¿‡é‚®ä»¶å‘é€")
            return
        
        logger.info(f"é‚®ä»¶å‘é€å¼€å§‹ - å‘é€æ–¹: {self.config['sender_email']}, æ¥æ”¶æ–¹: {self.config['receiver_email']}")
        
        try:
            self.output_manager.email_sender.send_html(
                sender=self.config['sender_email'],
                receiver=self.config['receiver_email'],
                password=self.config['email_password'],
                smtp_server=self.config['smtp_server'],
                smtp_port=self.config['smtp_port'],
                html_content=html_content,
                subject_prefix=self.config['subject_prefix'],
                use_ssl=self.config['use_ssl'],
                use_tls=self.config['use_tls']
            )
            logger.success("é‚®ä»¶å‘é€æˆåŠŸ")
        except Exception as e:
            logger.error(f"é‚®ä»¶å‘é€å¤±è´¥: {e}")
            logger.warning("é‚®ä»¶å‘é€å¤±è´¥ï¼Œä½†æŠ¥å‘Šå·²æˆåŠŸç”Ÿæˆå¹¶ä¿å­˜åˆ°æœ¬åœ°")
            # ä¸é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ç¨‹åºç»§ç»­è¿è¡Œ
    
    
    def _save_markdown_if_configured(self, markdown_content: str, current_time: str, target_date: str = None):
        """å¦‚æœé…ç½®äº†ä¿å­˜Markdownï¼Œåˆ™ä¿å­˜æŠ¥å‘Šã€‚
        
        Args:
            markdown_content: Markdownå†…å®¹
            current_time: å½“å‰æ—¶é—´
            target_date: æŸ¥è¯¢ç›®æ ‡æ—¥æœŸï¼ˆç”¨äºæ–‡ä»¶å‘½åï¼‰
        """
        if not self.config['save_markdown']:
            logger.debug("Markdownä¿å­˜å·²ç¦ç”¨")
            return
        
        logger.debug("MarkdownæŠ¥å‘Šä¿å­˜å¼€å§‹")
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            date_str = target_date if target_date else format_timezone_date()
            username = self._get_current_username()
            safe_username = sanitize_username(username)
            filename = f"{date_str}_{safe_username}_ARXIV_summary.md"
            logger.debug(f"ç”Ÿæˆæ–‡ä»¶å: {filename}")
            
            # ä¿å­˜æ–‡ä»¶
            filepath = self.output_manager.save_markdown_report(
                content=markdown_content,
                save_dir=self.config['save_directory'],
                filename=filename,
                username=username,
                target_date=target_date,
            )
            
            if not filepath:
                logger.error("MarkdownæŠ¥å‘Šä¿å­˜å¤±è´¥")
                
        except Exception as e:
            logger.error(f"MarkdownæŠ¥å‘Šä¿å­˜å¼‚å¸¸: {e}")
    
    def _save_html_report_if_configured(self, markdown_content: str, current_time: str, target_date: str = None):
        """å¦‚æœé…ç½®äº†ä¿å­˜Markdownï¼Œåˆ™åŒæ—¶ä¿å­˜HTMLæ ¼å¼çš„ç ”ç©¶æŠ¥å‘Šã€‚
        
        Args:
            markdown_content: Markdownå†…å®¹
            save_dir: ä¿å­˜ç›®å½•
            current_time: å½“å‰æ—¶é—´
            target_date: æŸ¥è¯¢ç›®æ ‡æ—¥æœŸï¼ˆç”¨äºæ–‡ä»¶å‘½åä¸å±•ç¤ºï¼‰
        """
        if not self.config['save_markdown']:
            logger.debug("HTMLæŠ¥å‘Šä¿å­˜å·²ç¦ç”¨")
            return
        
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            date_str = target_date if target_date else format_timezone_date()
            username = self._get_current_username()
            safe_username = sanitize_username(username)
            filename = f"{date_str}_{safe_username}_ARXIV_summary.html"
            
            # ä¿å­˜HTMLæ–‡ä»¶
            filepath = self.output_manager.save_markdown_report_as_html(
                markdown_content=markdown_content,
                save_dir=self.config['save_directory'],
                current_time=current_time,
                username=username,
                filename=filename,
                target_date=target_date,
            )
            
            if not filepath:
                logger.error("HTMLæŠ¥å‘Šä¿å­˜å¤±è´¥")
                
        except Exception as e:
            logger.error(f"HTMLæŠ¥å‘Šä¿å­˜å¼‚å¸¸: {e}")
            return None
    
    def _save_html_report_if_configured_separated(self, summary_content: str, detailed_analysis: str, brief_analysis: str, current_time: str, papers: list = None, target_date: str = None):
        """å¦‚æœé…ç½®äº†ä¿å­˜Markdownï¼Œåˆ™ä¿å­˜åˆ†ç¦»å†…å®¹çš„HTMLæ ¼å¼ç ”ç©¶æŠ¥å‘Šã€‚
        
        Args:
            summary_content: æ€»ç»“å†…å®¹
            detailed_analysis: è¯¦ç»†åˆ†æå†…å®¹
            brief_analysis: ç®€è¦åˆ†æå†…å®¹
            current_time: å½“å‰æ—¶é—´
            papers: è®ºæ–‡æ•°æ®åˆ—è¡¨ï¼Œç”¨äºç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
            target_date: æŸ¥è¯¢ç›®æ ‡æ—¥æœŸï¼ˆç”¨äºæ–‡ä»¶å‘½åä¸å±•ç¤ºï¼‰
            
        Returns:
            tuple: (HTMLæ–‡ä»¶è·¯å¾„, HTMLå†…å®¹å­—ç¬¦ä¸²)ï¼Œå¦‚æœæœªé…ç½®ä¿å­˜æˆ–å¤±è´¥åˆ™è¿”å›(None, None)
        """
        if not self.config['save_markdown']:
            logger.debug("HTMLæŠ¥å‘Šä¿å­˜å·²ç¦ç”¨")
            return None, None
        
        logger.debug("HTMLæŠ¥å‘Šç”Ÿæˆå¼€å§‹")
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            date_str = target_date if target_date else format_timezone_date()
            username = self._get_current_username()
            safe_username = sanitize_username(username)
            filename = f"{date_str}_{safe_username}_ARXIV_summary.html"
            logger.debug(f"ç”ŸæˆHTMLæ–‡ä»¶å: {filename}")
            
            # ä¿å­˜HTMLæ–‡ä»¶ï¼Œä¼ é€’åˆ†ç¦»çš„å†…å®¹
            filepath, html_content = self.output_manager.save_markdown_report_as_html_separated(
                summary_content=summary_content,
                detailed_analysis=detailed_analysis,
                brief_analysis=brief_analysis,
                save_dir=self.config['save_directory'],
                current_time=current_time,
                username=username,
                filename=filename,
                papers=papers,
                target_date=target_date,
            )
            
            if filepath:
                return filepath, html_content
            else:
                logger.error("HTMLæŠ¥å‘Šä¿å­˜å¤±è´¥")
                return None, None
                
        except Exception as e:
            logger.error(f"HTMLæŠ¥å‘Šä¿å­˜å¼‚å¸¸: {e}")
            return None, None
    
    def get_recommendations(self, specific_date=None):
        """è·å–æ¨èç»“æœï¼Œé€‚ç”¨äºStreamlitè°ƒç”¨ã€‚
        
        Args:
            specific_date: æŒ‡å®šæ—¥æœŸï¼Œæ ¼å¼ä¸ºYYYY-MM-DDï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ™ºèƒ½å›æº¯é€»è¾‘
        
        Returns:
            dict: åŒ…å«æ¨èç»“æœçš„å­—å…¸ï¼Œæ ¼å¼ä¸º:
            {
                'success': bool,  # æ˜¯å¦æˆåŠŸè·å–æ¨è
                'data': dict,     # æ¨èæ•°æ®ï¼ˆå¦‚æœæˆåŠŸï¼‰
                'error': str,     # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
                'current_time': str,  # å½“å‰æ—¶é—´
                'target_date': str    # ç›®æ ‡æ—¥æœŸ
            }
        """
        logger.info("ArXivæ¯æ—¥è®ºæ–‡æ¨èç³»ç»Ÿå¯åŠ¨")
        try:
            # åˆå§‹åŒ–ç»„ä»¶
            self._initialize_components()
            
            # è·å–å½“å‰æ—¶é—´
            current_time = self._get_current_time()
            
            # åŠ è½½ç ”ç©¶å…´è¶£
            research_interests = self._load_research_interests()
            
            # æ ¹æ®æ˜¯å¦æŒ‡å®šæ—¥æœŸé€‰æ‹©ä¸åŒçš„é€»è¾‘
            report_result = None
            target_date_str = None
            
            if specific_date:
                # æŒ‡å®šæ—¥æœŸæ¨¡å¼ï¼šç›´æ¥æŸ¥è¯¢æŒ‡å®šæ—¥æœŸ
                target_date_str = specific_date
                logger.info(f"è®ºæ–‡è·å–æ—¥æœŸ: {target_date_str} (ç”¨æˆ·æŒ‡å®šæ—¥æœŸ)")
                
                # æ‰§è¡Œæ¨èæµç¨‹
                logger.info("è®ºæ–‡æ¨èæµç¨‹å¼€å§‹")
                report_result = self.recommendation_engine.run(current_time, target_date_str)
                
                if report_result:
                    logger.success(f"åœ¨{target_date_str}æ‰¾åˆ°äº†è®ºæ–‡")
                else:
                    logger.warning(f"åœ¨{target_date_str}æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
            else:
                # æ™ºèƒ½å›æº¯æ¨¡å¼ï¼šå°è¯•è·å–æ˜¨å¤©å’Œå‰å¤©çš„è®ºæ–‡
                for days_back in [1, 2]:  # å…ˆå°è¯•æ˜¨å¤©ï¼Œå†å°è¯•å‰å¤©
                    target_date = get_timezone_aware_now() - timedelta(days=days_back)
                    target_date_str = target_date.strftime('%Y-%m-%d')
                    logger.info(f"è®ºæ–‡è·å–æ—¥æœŸ: {target_date_str} (å¾€å‰{days_back}å¤©)")
                    
                    # æ‰§è¡Œæ¨èæµç¨‹
                    logger.info("è®ºæ–‡æ¨èæµç¨‹å¼€å§‹")
                    report_result = self.recommendation_engine.run(current_time, target_date_str)
                    
                    if report_result:
                        logger.success(f"åœ¨{target_date_str}æ‰¾åˆ°äº†è®ºæ–‡")
                        break
                    else:
                        logger.warning(f"åœ¨{target_date_str}æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
            
            if report_result:
                logger.success("è®ºæ–‡æ¨èæµç¨‹å®Œæˆ")
                return {
                    'success': True,
                    'data': report_result,
                    'error': None,
                    'current_time': current_time,
                    'target_date': target_date_str
                }
            else:
                logger.warning("åœ¨ç›®æ ‡æ—¥æœŸèŒƒå›´å†…æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
                # æ ¹æ®æ¨¡å¼ç¡®å®šé”™è¯¯ä¿¡æ¯
                if specific_date:
                    error_msg = f"åœ¨æŒ‡å®šæ—¥æœŸ {target_date_str} æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡"
                else:
                    # æ™ºèƒ½å›æº¯æ¨¡å¼çš„é”™è¯¯ä¿¡æ¯
                    final_target_date_str = (get_timezone_aware_now() - timedelta(days=2)).strftime('%Y-%m-%d')
                    error_msg = f"åœ¨ç›®æ ‡æ—¥æœŸ {final_target_date_str} æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡"
                    target_date_str = final_target_date_str
                
                return {
                    'success': False,
                    'data': None,
                    'error': error_msg,
                    'current_time': current_time,
                    'target_date': target_date_str
                }
            
        except Exception as e:
            logger.error(f"ç³»ç»Ÿè¿è¡Œå¼‚å¸¸: {e}")
            return {
                'success': False,
                'data': None,
                'error': str(e),
                'current_time': None,
                'target_date': None
            }
    
    def save_reports(self, report_result: dict, current_time: str, target_date: str = None):
        """ä¿å­˜æŠ¥å‘Šæ–‡ä»¶ï¼Œé€‚ç”¨äºStreamlitè°ƒç”¨ã€‚
        
        Args:
            report_result: æ¨èç»“æœæ•°æ®
            current_time: å½“å‰æ—¶é—´
            target_date: æŸ¥è¯¢ç›®æ ‡æ—¥æœŸ
            
        Returns:
            dict: ä¿å­˜ç»“æœï¼Œæ ¼å¼ä¸º:
            {
                'markdown_saved': bool,
                'html_saved': bool,
                'html_content': str,
                'email_sent': bool
            }
        """
        try:
            # è·å–åˆ†ç¦»çš„å†…å®¹
            summary_content = report_result['summary']
            detailed_analysis = report_result['detailed_analysis']
            brief_analysis = report_result.get('brief_analysis', '')  # è·å–ç®€è¦åˆ†æå†…å®¹
            papers = report_result.get('papers', [])  # è·å–papersæ•°æ®ç”¨äºç»Ÿè®¡
            # ä¸ºå‘åå…¼å®¹ï¼Œåˆå¹¶å†…å®¹ç”¨äºMarkdownä¿å­˜
            markdown_content = summary_content + detailed_analysis + brief_analysis
            logger.debug("æŠ¥å‘Šå†…å®¹ç”Ÿæˆå®Œæˆ")
            
            logger.info("æŠ¥å‘Šä¿å­˜å’Œå‘é€å¼€å§‹")
            # ä¿å­˜ä¸ºMarkdown
            self._save_markdown_if_configured(markdown_content, current_time, target_date)
            # ä¿å­˜ä¸ºHTMLç ”ç©¶æŠ¥å‘Šï¼Œä¼ é€’åˆ†ç¦»çš„å†…å®¹å’Œpapersæ•°æ®
            html_filepath, html_content = self._save_html_report_if_configured_separated(summary_content, detailed_analysis, brief_analysis, current_time, papers, target_date)
            # å‘é€é‚®ä»¶ï¼Œä½¿ç”¨ç”Ÿæˆçš„HTMLå†…å®¹
            self._send_email_if_configured(html_content)
            
            return {
                'markdown_saved': self.config['save_markdown'],
                'html_saved': html_content is not None,
                'html_content': html_content,
                'html_filepath': html_filepath,
                'email_sent': self.config['send_email']
            }
        except Exception as e:
            logger.error(f"æŠ¥å‘Šä¿å­˜å¼‚å¸¸: {e}")
            return {
                'markdown_saved': False,
                'html_saved': False,
                'html_content': None,
                'email_sent': False
            }

    def run(self):
        """è¿è¡Œæ¨èç³»ç»Ÿä¸»æµç¨‹ã€‚"""
        logger.info("ArXivæ¯æ—¥è®ºæ–‡æ¨èç³»ç»Ÿå¯åŠ¨")
        try:
            # è·å–æ¨èç»“æœ
            result = self.get_recommendations()
            
            if result['success']:
                # ä¿å­˜æŠ¥å‘Š
                save_result = self.save_reports(result['data'], result['current_time'], target_date=result['target_date'])
                logger.success("ArXivæ¯æ—¥è®ºæ–‡æ¨èç³»ç»Ÿè¿è¡Œå®Œæˆ")
            else:
                logger.error(result['error'])
                sys.exit(0)  # æ­£å¸¸é€€å‡ºï¼Œå› ä¸ºè¿™ä¸æ˜¯é”™è¯¯æƒ…å†µ
            
        except Exception as e:
            logger.error(f"ç³»ç»Ÿè¿è¡Œå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)


def main():
    """ä¸»ç¨‹åºå…¥å£ã€‚"""
    try:
        # é…ç½®æ—¥å¿—ï¼ˆä½¿ç”¨é›†ä¸­åŒ– env é…ç½®æ¨¡å—ï¼‰
        logger.remove()  # ç§»é™¤é»˜è®¤å¤„ç†å™¨
        
        # æ—¥å¿—é…ç½®ï¼ˆç®€åŒ–ï¼šLOG_LEVELå’ŒLOG_FILEä½¿ç”¨å›ºå®šå€¼ï¼Œä¸å†ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        log_level = 'DEBUG'  # å›ºå®šä¸ºDEBUG
        log_to_console = get_bool('LOG_TO_CONSOLE', True)
        log_file = 'logs/arxiv_recommender.log'  # å›ºå®šè·¯å¾„
        
        # æ§åˆ¶å°æ—¥å¿—
        if log_to_console:
            logger.add(
                sys.stdout,
                format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
                level=log_level
            )
        
        # æ–‡ä»¶æ—¥å¿—
        if log_file:
            # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
            log_dir = os.path.dirname(log_file)
            if log_dir and not os.path.exists(log_dir):
                os.makedirs(log_dir, exist_ok=True)
            
            log_max_size = get_int('LOG_MAX_SIZE', 10) * 1024 * 1024  # è½¬æ¢ä¸ºå­—èŠ‚
            log_backup_count = get_int('LOG_BACKUP_COUNT', 5)
            
            logger.add(
                log_file,
                format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
                level=log_level,
                rotation=log_max_size,
                retention=log_backup_count,
                encoding="utf-8"
            )
        
        # åˆ›å»ºå¹¶è¿è¡ŒCLIåº”ç”¨
        cli_app = ArxivRecommenderCLI()
        cli_app.run()
        
    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        sys.exit(0)
    except Exception as e:
        logger.error(f"ç¨‹åºè¿è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
